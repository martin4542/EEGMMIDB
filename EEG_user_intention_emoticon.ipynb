{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyedflib import highlevel\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_1Dto2D(data, Y=9, X=9):\n",
    "    data_2D = np.zeros([Y, X]) # 나중에 바꾸기\n",
    "    data_2D[0] = (0,  \t   \t0, \t        0,          data[0],    data[1],    data[2], \t0,  \t    0, \t        0       )\n",
    "    data_2D[1] = (0,  \t   \t0,          0,          data[3],    0,          data[4],    0,          0,          0       )\n",
    "    data_2D[2] = (data[5],  data[6],    data[7],    data[8],    data[9],    data[10],   data[11],   data[12],   data[13])\n",
    "    data_2D[3] = (data[14], data[15],   data[16],   data[17],   data[18],   data[19],   data[20],   data[21],   data[22])\n",
    "    data_2D[4] = (data[23], data[24],   data[25],   data[26],   data[27],   data[28],   data[29],   data[30],   data[31])\n",
    "    data_2D[5] = (data[32], data[33],   data[34],   data[35],   data[36],   data[37],   data[38],   data[39],   data[40])\n",
    "    data_2D[6] = (data[41], data[42],   data[43],   data[44],   data[45],   data[46],   data[47],   data[48],   data[49])\n",
    "    data_2D[7] = (0,        data[50],   data[51],   data[52],   data[53],   data[54],   data[55],   data[56],   0       )\n",
    "    data_2D[8] = (0,        data[57],   0,          data[58],   data[59],   data[60],   0,          data[61],   0       )\n",
    "    return data_2D\n",
    "\n",
    "def dataset_1Dto2D(dataset_1D):\n",
    "    dataset_2D = np.zeros([dataset_1D.shape[0],9,9])\n",
    "    for i in range(dataset_1D.shape[0]):\n",
    "        dataset_2D[i] = data_1Dto2D(dataset_1D[i])\n",
    "    return dataset_2D\n",
    "\n",
    "def feature_normalize(data):\n",
    "    mean = data[data.nonzero()].mean()\n",
    "    sigma = data[data.nonzero()].std()\n",
    "    data_normalized = data\n",
    "    data_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean) / sigma\n",
    "    return data_normalized\n",
    "\n",
    "def norm_dataset(dataset_1D, NUM_CHANNEL=64):\n",
    "    norm_dataset_1D = np.zeros([dataset_1D.shape[0], NUM_CHANNEL])\n",
    "    for i in range(dataset_1D.shape[0]):\n",
    "        norm_dataset_1D[i] = feature_normalize(dataset_1D[i])        \n",
    "    return norm_dataset_1D\n",
    "\n",
    "def norm_dataset_1Dto2D(dataset_1D):\n",
    "    norm_dataset_2D = np.zeros([dataset_1D.shape[0],9,9])\n",
    "    for i in range(dataset_1D.shape[0]):\n",
    "        norm_dataset_2D[i] = feature_normalize(data_1Dto2D(dataset_1D[i]))\n",
    "    return norm_dataset_2D\n",
    "\n",
    "def windows(data, size):\n",
    "    start = 0\n",
    "    while ((start+size) < data.shape[0]):\n",
    "        yield int(start), int(start + size)\n",
    "        start += size\n",
    "\n",
    "def segment_signal_without_transition(data, window_size=160):\n",
    "    for (start, end) in windows(data, window_size):\n",
    "        if((len(data[start:end]) == window_size)):\n",
    "            if start == 0:\n",
    "                segments = np.array(data[start:end])\n",
    "            else:\n",
    "                segments = np.vstack([segments, data[start:end]])\n",
    "    return segments\n",
    "\n",
    "def delete_base_mean(signal, sampling_rate=160, yes_or_not='yes'):\n",
    "    total_len = int(len(signal)/sampling_rate)\n",
    "    base_signal = (signal[0:1*sampling_rate,:] + signal[1*sampling_rate:2*sampling_rate,:] + signal[2*sampling_rate:3*sampling_rate,:]) / 3 if yes_or_not == 'yes' else 0\n",
    "    for i in range(total_len):# delete base mean\n",
    "        signal[i*sampling_rate:(i+1)*sampling_rate, :] = signal[i*sampling_rate:(i+1)*sampling_rate, :] - base_signal\n",
    "    signal = norm_dataset(signal) # normalize data\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMI_SUBJECT = 109\n",
    "MMI_TRIAL = 14\n",
    "MMI_CHANNEL = 64\n",
    "DUR = 4\n",
    "SAMPLING_RATE = 160\n",
    "yes_or_not = 'yes'\n",
    "\n",
    "file_path = './eegmmidb_edf/S'\n",
    "save_path = './eegmmidb_emoticon_feature/S'\n",
    "\n",
    "left_right_chapter = [3, 4, 7, 8, 11, 12]\n",
    "feet_hand_chapter = [5, 6, 9, 10, 13, 14]\n",
    "problem_files = [87, 91, 99]\n",
    "\n",
    "for i in range(103, MMI_SUBJECT):\n",
    "    if i in problem_files: continue\n",
    "    MMI_right_hand = np.empty((0, 64))\n",
    "    MMI_left_hand = np.empty((0, 64))\n",
    "    MMI_both_hand = np.empty((0, 64))\n",
    "    MMI_both_feet = np.empty((0, 64))\n",
    "    \n",
    "    for j in range(1, MMI_TRIAL+1):\n",
    "        path = file_path + str(i+1).zfill(3) + '/s' +str(i+1).zfill(3) + 'R' + str(j).zfill(2) + '.edf'\n",
    "        if j in left_right_chapter:\n",
    "            # read edf files\n",
    "            signals, signal_header, header = highlevel.read_edf(path)\n",
    "            signals = signals.transpose(1, 0)\n",
    "            labels = header['annotations']\n",
    "            \n",
    "            # base mean 제거\n",
    "            delete_base_mean(signals)\n",
    "            # label에 따라 분류\n",
    "            for label in labels:\n",
    "                start_point = int(label[0]*SAMPLING_RATE)\n",
    "                DUR = int(label[1])\n",
    "                if label[2] == 'T1': #left fist\n",
    "                    MMI_left_hand = np.append(MMI_left_hand, signals[start_point:start_point + DUR*SAMPLING_RATE, :], axis=0)\n",
    "                elif label[2] == 'T2': #right fist\n",
    "                    MMI_right_hand = np.append(MMI_right_hand, signals[start_point:start_point + DUR*SAMPLING_RATE, :], axis=0)\n",
    "        elif j in feet_hand_chapter:\n",
    "            # read edf files\n",
    "            signals, signal_header, header = highlevel.read_edf(path)\n",
    "            signals = signals.transpose(1, 0)\n",
    "            labels = header['annotations']\n",
    "            # base mean 제거\n",
    "            delete_base_mean(signals)\n",
    "            # label에 따라 분류\n",
    "            for label in labels:\n",
    "                start_point = int(label[0]*SAMPLING_RATE)\n",
    "                DUR = int(label[1])\n",
    "                if label[2] == 'T1': # both hand\n",
    "                    MMI_both_hand = np.append(MMI_both_hand, signals[start_point:start_point + DUR*SAMPLING_RATE, :], axis=0)\n",
    "                elif label[2] == 'T2': # both feet\n",
    "                    MMI_both_feet = np.append(MMI_both_feet, signals[start_point:start_point + DUR*SAMPLING_RATE, :], axis=0)\n",
    "    \n",
    "    \n",
    "    left_hand_E = dataset_1Dto2D(MMI_left_hand)\n",
    "    right_hand_E = dataset_1Dto2D(MMI_right_hand)\n",
    "    both_hand_E = dataset_1Dto2D(MMI_both_hand)\n",
    "    both_feet_E = dataset_1Dto2D(MMI_both_feet)\n",
    "    \n",
    "    left_hand_E = np.reshape(left_hand_E, (-1, SAMPLING_RATE, 9, 9))\n",
    "    right_hand_E = np.reshape(right_hand_E, (-1, SAMPLING_RATE, 9, 9))\n",
    "    both_hand_E = np.reshape(both_hand_E, (-1, SAMPLING_RATE, 9, 9))\n",
    "    both_feet_E = np.reshape(both_feet_E, (-1, SAMPLING_RATE, 9, 9))\n",
    "    \n",
    "    MMI_left_hand = np.reshape(MMI_left_hand, (-1, SAMPLING_RATE, MMI_CHANNEL))\n",
    "    MMI_right_hand = np.reshape(MMI_right_hand, (-1, SAMPLING_RATE, MMI_CHANNEL))\n",
    "    MMI_both_hand = np.reshape(MMI_both_hand, (-1, SAMPLING_RATE, MMI_CHANNEL))\n",
    "    MMI_both_feet = np.reshape(MMI_both_feet, (-1, SAMPLING_RATE, MMI_CHANNEL))\n",
    "    \n",
    "    path = save_path + str(i+1).zfill(3)\n",
    "    if not os.path.exists(path): os.makedirs(path)\n",
    "    np.save(path+'/left_hand_E', left_hand_E)\n",
    "    np.save(path+'/right_hand_E', right_hand_E)\n",
    "    np.save(path+'/both_hand_E', both_hand_E)\n",
    "    np.save(path+'/both_feet_E', both_feet_E)\n",
    "    np.save(path+'/left_hand_C', MMI_left_hand)\n",
    "    np.save(path+'/right_hand_C', MMI_right_hand)\n",
    "    np.save(path+'/both_hand_C', MMI_both_hand)\n",
    "    np.save(path+'/both_feet_C', MMI_both_feet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.manual_seed_all(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "MMI_SUBJECT = 109\n",
    "MMI_TRIAL = 14\n",
    "MMI_CHANNEL = 64\n",
    "SAMPLING_RATE = 160\n",
    "BATCH_SIZE = 240\n",
    "N_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, nout, kernel=(5,5), stride=1, padding=1):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel, stride=stride, padding=padding, groups=nin)\n",
    "        nn.init.kaiming_normal_(self.depthwise.weight)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "        nn.init.kaiming_normal_(self.pointwise.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "    \n",
    "class EmotionNet(nn.Module):\n",
    "    def __init__(self, input_image=torch.zeros(1, 40, 1, 9, 9), kernel=(5,5), \n",
    "                 stride=1, padding=1, n_classes=4, n_units=128):\n",
    "        super(EmotionNet, self).__init__()\n",
    "        \n",
    "        n_window = input_image.shape[1]\n",
    "        n_channel = input_image.shape[2]\n",
    "        \n",
    "        # EEG-EmotionNet 2D ConvNet\n",
    "        self.conv1 = depthwise_separable_conv(n_channel, 32, kernel, stride=stride, padding=padding)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = depthwise_separable_conv(32, 64, kernel, stride=stride, padding=padding)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = depthwise_separable_conv(64, 128, kernel, stride=stride, padding=padding)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # EEG-EmotionNet Temporal 1D CNN\n",
    "        self.conv4 = nn.Conv2d(3 * 3 * 128, 128, (40, 1), stride=stride, padding=0)\n",
    "        nn.init.kaiming_normal_(self.conv4.weight)\n",
    "        \n",
    "        self.fc = nn.Linear(128, 128)\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "        self.max = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.get_device() == 0:\n",
    "            tmp = torch.zeros(x.shape[0], x.shape[1], 128, 3, 3).cuda()\n",
    "        else:\n",
    "            tmp = torch.zeros(x.shape[0], x.shape[1], 128, 3, 3).cpu()\n",
    "        for i in range(x.shape[1]):\n",
    "            img = x[:, i]\n",
    "            img = self.conv1(img) # 9x9 -> 7x7\n",
    "            img = F.elu(self.BatchNorm1(img))\n",
    "            img = self.conv2(img) # 7x7 -> 5x5\n",
    "            img = F.elu(self.BatchNorm2(img))\n",
    "            img = self.conv3(img) # 5x5 -> 3x3\n",
    "            img = F.elu(self.BatchNorm3(img))\n",
    "            tmp[:, i] = img\n",
    "            del img\n",
    "        \n",
    "        temp_conv = F.elu(self.conv4(tmp.reshape(x.shape[0], 3*128*3, x.shape[1], 1)))\n",
    "        temp_conv = temp_conv.reshape(temp_conv.shape[0], -1)\n",
    "        del tmp\n",
    "        x = temp_conv\n",
    "        x = F.elu(self.fc(x))\n",
    "        embedding = F.elu(self.fc1(x))\n",
    "        x = self.fc2(embedding)\n",
    "        return x, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(length, n_fold):\n",
    "    total_id = np.arange(length)\n",
    "    np.random.shuffle(total_id)\n",
    "    len_fold = int(length/n_fold)\n",
    "    train_id = []\n",
    "    test_id = []\n",
    "    for i in range(n_fold):\n",
    "        test_id.append(total_id[i*len_fold:(i+1)*len_fold])\n",
    "        train_id.append(np.hstack([total_id[0:i*len_fold], total_id[(i+1)*len_fold:-1]]))\n",
    "    return train_id, test_id\n",
    "\n",
    "class EEGImagesDataset(Dataset):\n",
    "    def __init__(self, label, image):\n",
    "        self.label = label\n",
    "        self.images = image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.images[idx]\n",
    "        label = self.label[idx]\n",
    "        sample = (image, label)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "def test_model(Model, testloader, criterion, is_cuda=True):\n",
    "    running_loss = 0.0\n",
    "    evaluation = []\n",
    "    \n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        input_img, labels = data\n",
    "        labels = labels.long()\n",
    "        input_img = input_img.to(torch.float32)\n",
    "        if is_cuda:\n",
    "            input_img = input_img.cuda()\n",
    "        outputs, _ = Model(input_img)\n",
    "        _, predicted = torch.max(outputs.cpu().data, 1)\n",
    "        evaluation.append((predicted==labels).tolist())\n",
    "        \n",
    "        loss = criterion(outputs, labels.cuda())\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    running_loss = running_loss / (i + 1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    running_acc = sum(evaluation)/len(evaluation)\n",
    "    return running_loss, running_acc\n",
    "\n",
    "def traintest_model(Model, trainloader, testloader, n_epoch=50, opti='SGD', learning_rate=0.0001,\n",
    "                    is_cuda=True, verbose=False):\n",
    "    if is_cuda:\n",
    "        model = Model().cuda()\n",
    "    else:\n",
    "        model = Model()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if opti == 'SGD': optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    elif opti == 'Adam': optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else: print('Optimizer not implemented')\n",
    "    \n",
    "    val_best = 0\n",
    "    exp_lr_scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        running_loss = 0.0\n",
    "        evaluation = []\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            labels = labels.long()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward\n",
    "            outputs, embedding = model(inputs.to(torch.float32).cuda())\n",
    "            _, predicted = torch.max(outputs.cpu().data, 1)\n",
    "            evaluation.append((predicted==labels).tolist())\n",
    "            \n",
    "            #backward\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            \n",
    "            #optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        exp_lr_scheduler.step()\n",
    "        \n",
    "        running_loss = running_loss/(i+1)\n",
    "        evaluation = [item for sublist in evaluation for item in sublist]\n",
    "        running_acc = sum(evaluation) / len(evaluation)\n",
    "        validation_loss, validation_acc = test_model(model, testloader, criterion, True)\n",
    "        \n",
    "        if validation_acc > val_best:\n",
    "            val_best = validation_acc\n",
    "            res = [running_loss, running_acc, validation_loss, validation_acc]\n",
    "        print('Intention\\t [%d, %4d]\\tloss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "              (epoch+1, n_epoch, running_loss, running_acc, validation_loss, validation_acc))\n",
    "    if verbose:\n",
    "        print('Finished Training Emotion \\n loss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "                 (running_loss, running_acc, validation_loss,validation_acc))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './eegmmidb_emoticon_feature/S'\n",
    "\n",
    "problem_files = [87, 91, 99]\n",
    "\n",
    "feature_len = [0]\n",
    "train_data = np.empty([0, 40, 9, 9])\n",
    "label = []\n",
    "\n",
    "def get_input_feature(train_data, feature_len, file='/left_hand_E.npy'):\n",
    "    for i in range(MMI_SUBJECT):\n",
    "        if i in problem_files: continue\n",
    "        left_hand_E = np.load(data_path + str(i+1).zfill(3) + file)\n",
    "        for i in range(40):\n",
    "            temp = np.empty((left_hand_E.shape[0], 40, 9, 9))\n",
    "            temp[:, i, :, :] = np.mean(left_hand_E[:,i*4:(i+1)*4,:,:], axis=1)\n",
    "        train_data = np.vstack([train_data, temp])\n",
    "        feature_len.append(len(train_data))\n",
    "    return train_data, feature_len\n",
    "\n",
    "def get_label(label_arr, a, b, label):\n",
    "    for i in range(a-b): label_arr.append(label)\n",
    "    return label_arr\n",
    "\n",
    "length = 0\n",
    "train_data, feature_len = get_input_feature(train_data, feature_len, file='/left_hand_E.npy')\n",
    "label = get_label(label, len(train_data), length, 0)\n",
    "length = len(train_data)\n",
    "\n",
    "train_data, feature_len = get_input_feature(train_data, feature_len, file='/right_hand_E.npy')\n",
    "label = get_label(label, len(train_data), length, 1)\n",
    "length = len(train_data)\n",
    "\n",
    "train_data, feature_len = get_input_feature(train_data, feature_len, file='/both_hand_E.npy')\n",
    "label = get_label(label, len(train_data), length, 2)\n",
    "length = len(train_data)\n",
    "\n",
    "train_data, feature_len = get_input_feature(train_data, feature_len, file='/both_feet_E.npy')\n",
    "label = get_label(label, len(train_data), length, 3)\n",
    "train_data = np.expand_dims(train_data, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time begin: time.struct_time(tm_year=2022, tm_mon=11, tm_mday=18, tm_hour=0, tm_min=10, tm_sec=15, tm_wday=4, tm_yday=322, tm_isdst=0)\n",
      "Intention\t [1,   50]\tloss: 0.8370\tAccuracy : 0.9834\t\tval-loss: 165.2443\tval-Accuracy : 0.0000\n",
      "Intention\t [2,   50]\tloss: 3.0310\tAccuracy : 0.9755\t\tval-loss: 533.5561\tval-Accuracy : 0.0000\n",
      "Intention\t [3,   50]\tloss: 6.4566\tAccuracy : 0.9650\t\tval-loss: 255.9822\tval-Accuracy : 0.0000\n",
      "Intention\t [4,   50]\tloss: 11.9758\tAccuracy : 0.9405\t\tval-loss: 116.9909\tval-Accuracy : 0.0000\n",
      "Intention\t [5,   50]\tloss: 2.2780\tAccuracy : 0.9300\t\tval-loss: 27.5229\tval-Accuracy : 0.0000\n",
      "Intention\t [6,   50]\tloss: 0.7526\tAccuracy : 0.8636\t\tval-loss: 8.5769\tval-Accuracy : 0.0000\n",
      "Intention\t [7,   50]\tloss: 0.7799\tAccuracy : 0.8077\t\tval-loss: 6.9650\tval-Accuracy : 0.0000\n",
      "Intention\t [8,   50]\tloss: 0.7115\tAccuracy : 0.7867\t\tval-loss: 7.5180\tval-Accuracy : 0.0000\n",
      "Intention\t [9,   50]\tloss: 0.8048\tAccuracy : 0.7832\t\tval-loss: 5.7562\tval-Accuracy : 0.0000\n",
      "Intention\t [10,   50]\tloss: 0.7270\tAccuracy : 0.8112\t\tval-loss: 5.8636\tval-Accuracy : 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\data set\\EEG emotion\\EEGMMIDB\\EEG_user_intention_emoticon.ipynb 셀 12\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m Trainloader \u001b[39m=\u001b[39m DataLoader(Train, batch_size\u001b[39m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Testloader \u001b[39m=\u001b[39m DataLoader(Test, batch_size\u001b[39m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m res \u001b[39m=\u001b[39m traintest_model(EmotionNet, Trainloader, Testloader, n_epoch\u001b[39m=\u001b[39;49mN_EPOCH, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                       learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m, opti\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mAdam\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Training for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m fold\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(r\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIntention End Training with \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mAccuracy : \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mval-loss: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mval-Accuracy : \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     (res[\u001b[39m0\u001b[39m], res[\u001b[39m1\u001b[39m], res[\u001b[39m2\u001b[39m], res[\u001b[39m3\u001b[39m]))\n",
      "\u001b[1;32md:\\data set\\EEG emotion\\EEGMMIDB\\EEG_user_intention_emoticon.ipynb 셀 12\u001b[0m in \u001b[0;36mtraintest_model\u001b[1;34m(Model, trainloader, testloader, n_epoch, opti, learning_rate, is_cuda, verbose)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m#backward\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mcuda())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m#optimize\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X14sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\jae\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jae\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EEG_train = EEGImagesDataset(label=label, image=train_data)\n",
    "n_fold = 10\n",
    "train_id, test_id = kfold(len(EEG_train), n_fold)\n",
    "\n",
    "Result = []\n",
    "for r in range(n_fold):\n",
    "    print(\"time begin:\", time.localtime())\n",
    "    Train = Subset(EEG_train, train_id[r])\n",
    "    Test = Subset(EEG_train, test_id[r])\n",
    "    Trainloader = DataLoader(Train, batch_size=BATCH_SIZE)\n",
    "    Testloader = DataLoader(Test, batch_size=BATCH_SIZE)\n",
    "    res = traintest_model(EmotionNet, Trainloader, Testloader, n_epoch=N_EPOCH, \n",
    "                          learning_rate=0.001, opti='Adam')\n",
    "    print('\\n Training for {} fold'.format(r+1))\n",
    "    print('Intention End Training with \\t loss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "        (res[0], res[1], res[2], res[3]))\n",
    "    Result.append(res)\n",
    "\n",
    "Result = np.mean(Result, axis=0)\n",
    "print('-'*20)\n",
    "print('Intention End Training with \\t loss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "    (Result[0], Result[1], Result[2], Result[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta EEG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time begin: time.struct_time(tm_year=2022, tm_mon=11, tm_mday=18, tm_hour=0, tm_min=30, tm_sec=20, tm_wday=4, tm_yday=322, tm_isdst=0)\n",
      "\n",
      " Training for 1 fold\n",
      "Intention\t [1,   50]\tloss: 99.7606\tAccuracy : 0.2567\t\tval-loss: 1.3867\tval-Accuracy : 0.2589\n",
      "Intention\t [2,   50]\tloss: 99.4098\tAccuracy : 0.2687\t\tval-loss: 1.3838\tval-Accuracy : 0.2694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\data set\\EEG emotion\\EEGMMIDB\\EEG_user_intention_emoticon.ipynb 셀 14\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X16sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m# get sum of embeddings\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X16sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X16sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     embeddings[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m embedding[idx]\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X16sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     labels_count[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/data%20set/EEG%20emotion/EEGMMIDB/EEG_user_intention_emoticon.ipynb#X16sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "learning_rate = 0.0001\n",
    "n_epoch = 50\n",
    "n_fold = 10\n",
    "Result = []\n",
    "\n",
    "QUERY_STEP = 10\n",
    "EEG_train = EEGImagesDataset(label=label, image=train_data)\n",
    "n_fold = 10\n",
    "train_id, test_id = kfold(len(EEG_train), n_fold)\n",
    "\n",
    "# define meta-loss\n",
    "def meta_loss(output_embeddings, labels, avg_embeddings):\n",
    "    distances = 0\n",
    "    for idx in range(len(output_embeddings)):\n",
    "        temp = 0\n",
    "        for k in range(len(avg_embeddings)):\n",
    "            if labels[idx] == k:\n",
    "                distances += torch.sum(torch.abs(output_embeddings[idx] - avg_embeddings[k]))\n",
    "            else:\n",
    "                temp += torch.exp(torch.sum(-torch.abs(output_embeddings[idx] - avg_embeddings[k])))\n",
    "        distances += torch.log(temp)\n",
    "    distances /= len(output_embeddings)\n",
    "    return distances\n",
    "\n",
    "print(\"time begin:\", time.localtime())\n",
    "for r in range(n_fold):\n",
    "    print('\\n Training for {} fold'.format(r+1))\n",
    "    \n",
    "    Train = Subset(EEG_train, train_id[r])\n",
    "    Test = Subset(EEG_train, test_id[r])\n",
    "    Trainloader = DataLoader(Train, batch_size=BATCH_SIZE)\n",
    "    Testloader = DataLoader(Test, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # spilt query sample and support sample\n",
    "    # random sampling only\n",
    "    # query set is implemented every 10 steps \n",
    "    \n",
    "    # load model & set criterion, optimizer\n",
    "    model = EmotionNet().cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    val_best = 0\n",
    "    exp_lr_scheduler = StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        embeddings = np.zeros((4, 128)) # save each classes' embeddings\n",
    "        labels_count = np.zeros(4) # get labels count\n",
    "        num_of_step = 1\n",
    "        running_loss = 0.0\n",
    "        evaluation = []\n",
    "        \n",
    "        for i, data in enumerate(Trainloader):\n",
    "            if num_of_step % QUERY_STEP == 0: # query set training (every 10 stepts)\n",
    "                # get average embeddings\n",
    "                for i in range(len(embeddings)):\n",
    "                    embeddings[i] /= labels_count[i]\n",
    "                embeddings = torch.Tensor(embeddings).cuda() # for loss calculation\n",
    "                \n",
    "                # get the inputs\n",
    "                inputs, labesl = data\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs, embedding = model(inputs.to(torch.float32).cuda())\n",
    "                \n",
    "                # backward\n",
    "                loss = meta_loss(embedding, labels, embeddings) # get meta loss\n",
    "                loss.backward()\n",
    "                \n",
    "                # optimize\n",
    "                optimizer.step()\n",
    "                \n",
    "                embeddings = np.zeros((4, 128)) # initialize embedding averagess\n",
    "                labels_count = np.zeros(4) # initialize label count\n",
    "            \n",
    "            else: # support set training\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                labels = labels.long()\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs, embedding = model(inputs.to(torch.float32).cuda())\n",
    "                _, predicted = torch.max(outputs.cpu().data, 1)\n",
    "                evaluation.append((predicted==labels).tolist())\n",
    "                \n",
    "                # backward\n",
    "                loss = criterion(outputs, labels.cuda())\n",
    "                loss.backward()\n",
    "                \n",
    "                # optimize\n",
    "                optimizer.step()\n",
    "                \n",
    "                # get sum of embeddings\n",
    "                for idx, i in enumerate(labels):\n",
    "                    embeddings[i] += embedding[idx].cpu().detach().data.numpy()\n",
    "                    labels_count[i] += 1\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "        exp_lr_scheduler.step()\n",
    "        \n",
    "        running_loss = running_loss/(i+1)\n",
    "        evaluation = [item for sublist in evaluation for item in sublist]\n",
    "        running_acc = sum(evaluation) / len(evaluation)\n",
    "        validation_loss, validation_acc = test_model(model, Testloader, criterion, True)\n",
    "        \n",
    "        if validation_acc > val_best:\n",
    "            val_best = validation_acc\n",
    "            res = [running_loss, running_acc, validation_loss, validation_acc]\n",
    "        print('Intention\\t [%d, %4d]\\tloss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "              (epoch+1, n_epoch, running_loss, running_acc, validation_loss, validation_acc))\n",
    "    \n",
    "    print('Finished Training Intention \\n loss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "            (running_loss, running_acc, validation_loss,validation_acc))\n",
    "    \n",
    "    Result.append(res)\n",
    "\n",
    "Result = np.mean(Result, axis=0)\n",
    "print('-'*20)\n",
    "print('Intention End Training with \\t loss: %.4f\\tAccuracy : %.4f\\t\\tval-loss: %.4f\\tval-Accuracy : %.4f' %\n",
    "    (Result[0], Result[1], Result[2], Result[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Learning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_file = 'D:/data set/EEG emotion/EEGMMIDB/result/EEG-intention_meta_result.txt'\n",
    "f = open(result_file, 'r')\n",
    "\n",
    "results = []\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line:break\n",
    "    if (len(line) < 8) and (line != '\\n'):\n",
    "        results.append(float(line[:-1]))\n",
    "\n",
    "normal_results = np.array(results[500:]).reshape((-1,10))\n",
    "meta_results = np.array(results[:500]).reshape((-1,10))\n",
    "\n",
    "normal_avg = np.mean(normal_results, axis=0)\n",
    "meta_avg = np.mean(meta_results, axis=0)\n",
    "normal_std = np.std(normal_results, axis=0)\n",
    "meta_std = np.std(meta_results, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(epoch, normal_avg, yerr=normal_std, capsize=4, marker='o', markersize=3, label='meta training')\n",
    "plt.errorbar(epoch, meta_avg, yerr=meta_std, capsize=4, marker='s', markersize=3, label='Intention Net')\n",
    "plt.title('EEG-meta training result comparison')\n",
    "plt.xlabel('epooch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc469e6629064644558a07d62555f1d641af299a4c204c097a4b502f24b30db0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
