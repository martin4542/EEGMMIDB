{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "from scipy import io\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipl(a,b):\n",
    "    sumofab=0.0\n",
    "    for i in range(len(a)):\n",
    "        temp=a[i]*b[i]\n",
    "        sumofab+=temp\n",
    "    return sumofab\n",
    " \n",
    "def corrcoef(x,y):         # Pearson correlation coefficient\n",
    "    n=len(x)\n",
    "    sum1=sum(x)\n",
    "    sum2=sum(y)\n",
    "    sumofxy=multipl(x,y)\n",
    "    sumofx2 = sum([pow(i,2) for i in x])\n",
    "    sumofy2 = sum([pow(j,2) for j in y])\n",
    "    num=sumofxy-(float(sum1)*float(sum2)/n)\n",
    "    den=sqrt((sumofx2-float(sum1**2)/n)*(sumofy2-float(sum2**2)/n))\n",
    "    return num/den\n",
    "\n",
    "def read_dat(file):                      #read_dat('D:\\\\file.dat')\n",
    "    d = pickle.load(open(file, 'rb'), encoding='latin1')\n",
    "    return d\n",
    "\n",
    "def takehalfnums(matrix):                #symmetric matrix중 절반숫자만 뽑아 한줄 array로 반환\n",
    "    halfnums=[]\n",
    "    length=len(matrix)\n",
    "    for i in range(length):\n",
    "        for j in range(i):\n",
    "            halfnums.append(matrix[i][j])\n",
    "    return np.array(halfnums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEAP_SUBJECT = 32\n",
    "DEAP_TRIAL = 40\n",
    "DEAP_CHANNEL = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DEAP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deap_raw_data.shape:  (32, 40, 40, 8064)\n"
     ]
    }
   ],
   "source": [
    "DEAP_PATH = 'D:\\\\EEG_datasets\\\\DEAP\\\\data_preprocessed_python\\\\'\n",
    "\n",
    "deap_raw_data = []\n",
    "for i in tqdm(range(DEAP_SUBJECT)):\n",
    "    d = pickle.load(open(DEAP_PATH +'s'+str(i+1).zfill(2)+'.dat', 'rb'), encoding='latin1')\n",
    "    #labels = d['labels']\n",
    "    deap_raw_data.append(d['data'])\n",
    "deap_raw_data = np.array(deap_raw_data)\n",
    "\n",
    "print('deap_raw_data.shape: ', deap_raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x10000 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,100))\n",
    "for i in range(32):\n",
    "    for j in range(1):\n",
    "        plt.subplot(32, 1, 1*i+j+1)\n",
    "        plt.plot(deap_raw_data[0,0,1*i+j, 800:800+512])\n",
    "        plt.xticks(np.arange(0, 512, step=128), [\"{:0<2d}\".format(x) for x in np.arange(0, 512, step=128)], \n",
    "           fontsize=20\n",
    "          )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature of DEAP\n",
    "### Calculate `single-channel` features of DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deap_single_channel.shape:  (32, 40, 32, 10)\n"
     ]
    }
   ],
   "source": [
    "deap_single_channel = np.zeros((DEAP_SUBJECT,DEAP_TRIAL,DEAP_CHANNEL,10))\n",
    "for i in tqdm(range(DEAP_SUBJECT)):\n",
    "    for x in range(DEAP_TRIAL):\n",
    "        for y in range(DEAP_CHANNEL):\n",
    "            for z in range(10):\n",
    "                if z<9:\n",
    "                    data_cut=deap_raw_data[i][x][y][(807*z):(807*(z+1))]\n",
    "                else:\n",
    "                    data_cut=deap_raw_data[i][x][y][(807*z):8064]\n",
    "                deap_single_channel[i][x][y][z]=np.mean(data_cut)\n",
    "\n",
    "print('deap_single_channel.shape: ', deap_single_channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `channel-wise` features of DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 464.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deap_channel_wise.shape:  (32, 40, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "deap_channel_wise = np.zeros((DEAP_SUBJECT,DEAP_TRIAL,DEAP_CHANNEL,DEAP_CHANNEL))\n",
    "for i in tqdm(range(DEAP_SUBJECT)):\n",
    "    for x in range(DEAP_TRIAL):     \n",
    "        deap_channel_wise[i][x] = np.corrcoef(deap_single_channel[i][x])\n",
    "                \n",
    "print('deap_channel_wise.shape: ', deap_channel_wise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `half data` of channel-wise feature in DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deap_half_data.shape:  (1280, 496)\n",
      "deap_label.shape:  (1280, 32)\n"
     ]
    }
   ],
   "source": [
    "deap_half_data = []                                                 #(1280,496)\n",
    "deap_label = np.zeros((DEAP_SUBJECT*DEAP_TRIAL, DEAP_SUBJECT))      #(1280,32) one_hot\n",
    "for video in range(DEAP_TRIAL):  # 40\n",
    "    for user in range(DEAP_SUBJECT):  #32\n",
    "        deap_half_data.append(takehalfnums(deap_channel_wise[user][video]))\n",
    "        deap_label[DEAP_SUBJECT*video+user][user] = 1\n",
    "deap_half_data = np.array(deap_half_data)\n",
    "\n",
    "idx = np.arange(DEAP_SUBJECT*DEAP_TRIAL)\n",
    "np.random.shuffle(idx)\n",
    "deap_half_data = deap_half_data[idx]\n",
    "deap_label = deap_label[idx]\n",
    "\n",
    "print('deap_half_data.shape: ', deap_half_data.shape)\n",
    "print('deap_label.shape: ', deap_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold validation / `channel-wise feature` / DEAP / MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:21<00:00, 20.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984375\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val_samples = len(deap_half_data) // k\n",
    "num_epochs = 100\n",
    "deap_mlp_acc = []\n",
    "for i in tqdm(range(k)):\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    test_data = deap_half_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    test_label = deap_label[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [deap_half_data[:i * num_val_samples],\n",
    "         deap_half_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_label = np.concatenate(\n",
    "        [deap_label[:i * num_val_samples],\n",
    "         deap_label[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='softmax', input_shape=(496, )))\n",
    "#     model.add(Dense(64, activation='relu', input_shape=(496, )))\n",
    "#     model.add(Dense(32, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "    model.fit(partial_train_data, partial_train_label, validation_data=(test_data, test_label), \n",
    "              epochs=num_epochs, batch_size=10, verbose=0, callbacks=[early_stop])\n",
    "    # 검증 세트로 모델 평가\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_label, verbose=0)\n",
    "    deap_mlp_acc.append(test_acc)\n",
    "    \n",
    "deap_mlp_acc_ = np.mean(deap_mlp_acc)\n",
    "print(deap_mlp_acc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten `single-channel` feature of DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deap_single_flatten.shape:  (1280, 320)\n",
      "deap_label.shape:  (1280, 32)\n"
     ]
    }
   ],
   "source": [
    "deap_single_flatten = []                                            #(1280,320)\n",
    "deap_label = np.zeros((DEAP_SUBJECT*DEAP_TRIAL, DEAP_SUBJECT))      #(1280,32) one_hot\n",
    "for video in range(DEAP_TRIAL):\n",
    "    for user in range(DEAP_SUBJECT):\n",
    "        deap_single_flatten.append(deap_single_channel[user][video].reshape(320,))\n",
    "        deap_label[DEAP_SUBJECT*video+user][user] = 1\n",
    "deap_single_flatten = np.array(deap_single_flatten)\n",
    "\n",
    "print('deap_single_flatten.shape: ', deap_single_flatten.shape)\n",
    "print('deap_label.shape: ', deap_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold validation / `single-channel feature` / DEAP / MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:29<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30390626\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val_samples = len(deap_single_flatten) // k\n",
    "num_epochs = 100\n",
    "deap_mlp_acc_s = []\n",
    "for i in tqdm(range(k)):\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    test_data = deap_single_flatten[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    test_label = deap_label[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [deap_single_flatten[:i * num_val_samples],\n",
    "         deap_single_flatten[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_label = np.concatenate(\n",
    "        [deap_label[:i * num_val_samples],\n",
    "         deap_label[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='softmax', input_shape=(320, )))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(32, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')\n",
    "    model.fit(partial_train_data, partial_train_label, validation_data=(test_data, test_label), \n",
    "              epochs=num_epochs, verbose=0, callbacks=[early_stop])\n",
    "    # 검증 세트로 모델 평가\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_label, verbose=0)\n",
    "    deap_mlp_acc_s.append(test_acc)\n",
    "    \n",
    "deap_mlp_acc_s_ = np.mean(deap_mlp_acc_s)\n",
    "print(deap_mlp_acc_s_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Experiment on MMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMIDB_SUBJECT = 100\n",
    "MMIDB_TRIAL = 12 * 5\n",
    "MMIDB_CHANNEL = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MMIDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmidb_raw_data.shape:  (100, 60, 64, 9600)\n"
     ]
    }
   ],
   "source": [
    "MMIDB_PATH = './eegmmidb_mat\\\\'\n",
    "\n",
    "mmidb_raw_data = []\n",
    "for i in tqdm(range(MMIDB_SUBJECT)):\n",
    "    data = []\n",
    "    for j in range(12):\n",
    "        mat_file = io.loadmat(MMIDB_PATH + 'S' + str(i+1).zfill(3) + '/' + \n",
    "                              'S' + str(i+1).zfill(3) + 'R' +str(3+j).zfill(2))     # S001/S001R01.mat\n",
    "        data.append(mat_file['record'][:MMIDB_CHANNEL, :9600])\n",
    "        data.append(mat_file['record'][:MMIDB_CHANNEL, 160:160+9600])\n",
    "        data.append(mat_file['record'][:MMIDB_CHANNEL, 320:320+9600])\n",
    "        data.append(mat_file['record'][:MMIDB_CHANNEL, 480:480+9600])\n",
    "        data.append(mat_file['record'][:MMIDB_CHANNEL, 540:540+9600])\n",
    "    mmidb_raw_data.append(data)\n",
    "mmidb_raw_data = np.array(mmidb_raw_data)\n",
    "\n",
    "print('mmidb_raw_data.shape: ', mmidb_raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature of EEGMMIDB\n",
    "### Calculate `single-channel` features of EEGMMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmidb_single_channel.shape:  (100, 60, 64, 10)\n"
     ]
    }
   ],
   "source": [
    "mmidb_single_channel = np.zeros((MMIDB_SUBJECT,MMIDB_TRIAL,MMIDB_CHANNEL,10))\n",
    "for i in tqdm(range(MMIDB_SUBJECT)):\n",
    "    for x in range(MMIDB_TRIAL):\n",
    "        for y in range(MMIDB_CHANNEL):\n",
    "            for z in range(10):\n",
    "                data_cut=mmidb_raw_data[i][x][y][(960*z):(960*(z+1))]\n",
    "                mmidb_single_channel[i][x][y][z]=np.mean(data_cut)\n",
    "\n",
    "print('mmidb_single_channel.shape: ', mmidb_single_channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `channel-wise` features of EEGMMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [08:51<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmidb_channel_wise.shape:  (100, 60, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "mmidb_channel_wise = np.zeros((MMIDB_SUBJECT,MMIDB_TRIAL,MMIDB_CHANNEL,MMIDB_CHANNEL))\n",
    "for i in tqdm(range(MMIDB_SUBJECT)):\n",
    "    for x in range(MMIDB_TRIAL):     \n",
    "        for y in range(MMIDB_CHANNEL):          \n",
    "            for z in range(MMIDB_CHANNEL):      \n",
    "                a = mmidb_single_channel[i][x][y]\n",
    "                b = mmidb_single_channel[i][x][z]\n",
    "                mmidb_channel_wise[i][x][y][z] = corrcoef(a,b)\n",
    "            \n",
    "print('mmidb_channel_wise.shape: ', mmidb_channel_wise.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate `half data` of channel-wise feature in EEGMMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmidb_half_data.shape:  (6000, 2016)\n",
      "mmidb_label.shape:  (6000, 100)\n"
     ]
    }
   ],
   "source": [
    "mmidb_half_data = []                                                    #(6000,2016)\n",
    "mmidb_label = np.zeros((MMIDB_SUBJECT*MMIDB_TRIAL, MMIDB_SUBJECT))      #(6000,100) one_hot\n",
    "for video in range(MMIDB_TRIAL):\n",
    "    for user in range(MMIDB_SUBJECT):\n",
    "        mmidb_half_data.append(takehalfnums(mmidb_channel_wise[user][video]))\n",
    "        mmidb_label[MMIDB_SUBJECT*video+user][user] = 1\n",
    "mmidb_half_data = np.array(mmidb_half_data)\n",
    "\n",
    "idx = np.arange(MMIDB_SUBJECT*MMIDB_TRIAL)\n",
    "np.random.shuffle(idx)\n",
    "mmidb_half_data = mmidb_half_data[idx]\n",
    "mmidb_label = mmidb_label[idx]\n",
    "\n",
    "print('mmidb_half_data.shape: ', mmidb_half_data.shape)\n",
    "print('mmidb_label.shape: ', mmidb_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold validation / `channel-wise feature` / EEGMMIDB / MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [09:21<00:00, 56.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9783333\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val_samples = len(mmidb_half_data) // k\n",
    "num_epochs = 1000\n",
    "mmidb_mlp_acc = []\n",
    "for i in tqdm(range(k)):\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    test_data = mmidb_half_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    test_label = mmidb_label[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [mmidb_half_data[:i * num_val_samples],\n",
    "         mmidb_half_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_label = np.concatenate(\n",
    "        [mmidb_label[:i * num_val_samples],\n",
    "         mmidb_label[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1024, input_dim=2016, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=512, input_dim=1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=100))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    # Training\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "    model.fit(partial_train_data, partial_train_label, epochs=num_epochs, verbose=0, shuffle=True, \n",
    "              validation_data=(test_data, test_label), callbacks=[early_stop])\n",
    "\n",
    "    # 검증 세트로 모델 평가\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_label, verbose=0)\n",
    "    mmidb_mlp_acc.append(test_acc)\n",
    "    \n",
    "mmidb_mlp_acc_ = np.mean(mmidb_mlp_acc)\n",
    "print(mmidb_mlp_acc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten `single-channel` feature of EEGMMIDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmidb_single_flatten.shape:  (6000, 640)\n",
      "mmidb_label_s.shape:  (6000, 100)\n"
     ]
    }
   ],
   "source": [
    "mmidb_single_flatten = []                                                 #(6000,640)\n",
    "mmidb_label_s = np.zeros((MMIDB_SUBJECT*MMIDB_TRIAL, MMIDB_SUBJECT))      #(6000,64) one_hot\n",
    "for video in range(MMIDB_TRIAL):\n",
    "    for user in range(MMIDB_SUBJECT):\n",
    "        mmidb_single_flatten.append(mmidb_single_channel[user][video].reshape(640,))\n",
    "        mmidb_label_s[MMIDB_SUBJECT*video+user][user] = 1\n",
    "mmidb_single_flatten = np.array(mmidb_single_flatten)\n",
    "\n",
    "idx = np.arange(MMIDB_SUBJECT*MMIDB_TRIAL)\n",
    "np.random.shuffle(idx)\n",
    "mmidb_single_flatten = mmidb_single_flatten[idx]\n",
    "mmidb_label_s = mmidb_label_s[idx]\n",
    "\n",
    "print('mmidb_single_flatten.shape: ', mmidb_single_flatten.shape)\n",
    "print('mmidb_label_s.shape: ', mmidb_label_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold validation / `single-channel feature` / EEGMMIDB / MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:48<00:00,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10416667\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val_samples = len(mmidb_single_flatten) // k\n",
    "num_epochs = 1000\n",
    "mmidb_mlp_acc_s = []\n",
    "for i in tqdm(range(k)):\n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    test_data = mmidb_single_flatten[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    test_label = mmidb_label_s[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate(\n",
    "        [mmidb_single_flatten[:i * num_val_samples],\n",
    "         mmidb_single_flatten[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_label = np.concatenate(\n",
    "        [mmidb_label_s[:i * num_val_samples],\n",
    "         mmidb_label_s[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(units=100, input_dim=640, activation='softmax'))\n",
    "    model.add(Dense(units=256, input_dim=640, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=100, input_dim=256 ))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Training\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "    model.fit(partial_train_data, partial_train_label, epochs=num_epochs, verbose=0, shuffle=True, \n",
    "              validation_data=(test_data, test_label), callbacks=[early_stop])\n",
    "\n",
    "    # 검증 세트로 모델 평가\n",
    "    test_loss, test_acc = model.evaluate(test_data, test_label, verbose=0)\n",
    "    mmidb_mlp_acc_s.append(test_acc)\n",
    "\n",
    "mmidb_mlp_acc_s_ = np.mean(mmidb_mlp_acc_s)\n",
    "print(mmidb_mlp_acc_s_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy of using single-channel feature and channel-wise feature\n",
    "| accuracy | single-channel feature | channel-wise feature |\n",
    "|---|:---:|---:|\n",
    "| EEGMMIDB | 66.5167% | 98.15% |\n",
    "| DEAP     | 87.0968% | 99.8438% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy of reduce trials\n",
    "| trial | DEAP | EEGMMIDB |\n",
    "|---|:---:|---:|\n",
    "| 40 | 99.8438% |    -   |\n",
    "| 39 | 99.9194% |    -   |\n",
    "| 38 | 99.9174% |    -   |\n",
    "| 37 | 99.9153% |    -   |\n",
    "| 36 | 99.9130% |    -   |\n",
    "| 35 |100.0000% |    -   |\n",
    "| 34 |100.0000% |    -   |\n",
    "| 33 |100.0000% |    -   |\n",
    "| 32 |100.0000% |    -   |\n",
    "| 31 |100.0000% |    -   |\n",
    "| 30 | 99.8958% |    -   |\n",
    "| 29 | 99.8913% |    -   |\n",
    "| 28 | 99.8876% |    -   |\n",
    "| 27 | 99.8837% |    -   |\n",
    "| 26 |100.0000% |    -   |\n",
    "| 25 | 99.8750% |    -   |\n",
    "| 24 |100.0000% |    -   |\n",
    "| 23 | 99.8630% |    -   |\n",
    "| 22 | 99.8571% |    -   |\n",
    "| 21 | 99.8507% |    -   |\n",
    "| 20 | 99.8438% |    -   |\n",
    "| 19 | 99.8333% |    -   |\n",
    "| 18 | 99.8246% |    -   |\n",
    "| 17 | 99.8148% |    -   |\n",
    "| 16 | 99.8039% |    -   |\n",
    "| 15 | 99.5833% |    -   |\n",
    "| 14 | 99.7727% |    -   |\n",
    "| 13 | 99.7561% |    -   |\n",
    "| 12 | 99.7368% | 98.15% |\n",
    "| 11 | 99.7143% | 97.6000% |\n",
    "| 10 |100.0000% | 97.5600% |\n",
    "|  9 |100.0000% | 97.2001% |\n",
    "|  8 |100.0000% | 96.1750% |\n",
    "|  7 |100.0000% | 95.0286% |\n",
    "|  6 |100.0000% | 92.4000% |\n",
    "|  5 | 99.3750% | 89.6800% |\n",
    "|  4 | 98.3333% | 85.4000% |\n",
    "|  3 | 96.6667% | 80.2000% |\n",
    "|  2 | 94.9999% | 64.1000% |\n",
    "|  1 | 00.0000% | 25.0000% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy of reduce channels\n",
    "| channels | DEAP | EEGMMIDB|\n",
    "|----------|:----:|--------:|\n",
    "| 64 |     -    | 98.15% |\n",
    "| 32 |100.0000% | 94.5167% |\n",
    "| 14 | 99.5238% | 56.0167% |\n",
    "| 8  | 97.1094% | 26.0999% |\n",
    "| 5  | 81.0156% | % |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "466px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
